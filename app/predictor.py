# kinovanga/predictor.py
import pandas as pd
import numpy as np
import joblib
import gc
from tqdm import tqdm

# –í–Ω–µ—à–Ω–∏–µ –∏–º–ø–æ—Ä—Ç—ã –≤–≤–µ—Ä—Ö—É
from app.data_loader import load_imdb_chunked
from app.preprocessing import create_features
from app.nlp import PlotVectorizer
from app.model import MovieRatingPredictor
from utils.counter import count_lines_gz


class Kinovanga:
    def __init__(self, model_path: str = None):
        if model_path:
            data = joblib.load(model_path)
            self.predictor = data['model']
            self.vectorizer = data['vectorizer']
            self.director_avg = data['director_avg']
        else:
            self.predictor = None
            self.vectorizer = None
            self.director_avg = {}

    def train_on_chunks(
        self,
        basics_path: str,
        ratings_path: str,
        crew_path: str,
        chunksize: int = 10000,
        max_chunks: int = None,
        val_split: float = 0.2
    ):
        print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –ö–∏–Ω–æ–í–∞–Ω–≥–∏ –Ω–∞ —á–∞–Ω–∫–∞—Ö...")

        total_lines = count_lines_gz(basics_path) - 1  # –º–∏–Ω—É—Å –∑–∞–≥–æ–ª–æ–≤–æ–∫
        total_chunks = (total_lines + chunksize - 1) // chunksize

        print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {chunksize}")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –¥–∞–Ω–Ω—ã—Ö: ~{total_lines:,} —Å—Ç—Ä–æ–∫")
        print(f"  ‚Ä¢ –û—Ü–µ–Ω–∫–∞ —á–∞–Ω–∫–æ–≤: ~{total_chunks}")
        print(f"  ‚Ä¢ –ú–∞–∫—Å–∏–º—É–º —á–∞–Ω–∫–æ–≤: {max_chunks if max_chunks else f'–≤—Å–µ ({total_chunks})'}")
        print(f"  ‚Ä¢ –í–∞–ª–∏–¥–∞—Ü–∏—è: {val_split * 100:.0f}%")

        # --- 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞ ---
        print("üß† –û–±—É—á–∞—é TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –Ω–∞ –ø–µ—Ä–≤–æ–º —á–∞–Ω–∫–µ...")
        chunk_iter = load_imdb_chunked(basics_path, ratings_path, crew_path, chunksize)
        
        # –¢–æ–ª—å–∫–æ –¥–ª—è TF-IDF
        first_chunk = next(chunk_iter)
        first_chunk = create_features(first_chunk)
        
        if 'description' not in first_chunk.columns:
            raise KeyError("–ö–æ–ª–æ–Ω–∫–∞ 'description' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ create_features().")
        
        self.vectorizer = PlotVectorizer(max_features=100)
        self.vectorizer.fit_transform(first_chunk['description'])

        # --- 2. –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Ä–µ–∂–∏—Å—Å—ë—Ä–∞–º –∏ –æ–±—É—á–µ–Ω–∏–µ ---
        print("üìä –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å...")
        director_ratings = {}  # {director: [ratings]}

        def update_director_stats(df):
            for _, row in df[['directors', 'averageRating']].iterrows():
                director = row['directors']
                rating = row['averageRating']
                if pd.notna(director) and pd.notna(rating):
                    if director not in director_ratings:
                        director_ratings[director] = []
                    director_ratings[director].append(rating)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        self.predictor = MovieRatingPredictor()
        val_history = []
        total_chunks = 0

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π —á–∞–Ω–∫ –≤ –ø–æ—Ç–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        chunks = [first_chunk] + list(chunk_iter)

        for chunk in chunks:
            if max_chunks and total_chunks >= max_chunks:
                break

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ü–ï–†–ï–î —Ç–µ–º, –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å director_avg
            update_director_stats(chunk)

            # –°–æ–∑–¥–∞—ë–º director_avg_map –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            director_avg_map = {k: np.mean(v) for k, v in director_ratings.items()}

            # –û–¥–∏–Ω —Ä–∞–∑ ‚Äî —Å–æ–∑–¥–∞—ë–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –∞–∫—Ç—É–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
            df = create_features(chunk, director_avg_map=director_avg_map)

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ —Ä–µ–π—Ç–∏–Ω–≥–∞
            df = df.dropna(subset=['averageRating'])

            X_text = self.vectorizer.transform(df['description'])
            X_num = df[['startYear', 'runtimeMinutes', 'director_avg_rating', 'is_remake']].values
            X = np.hstack([X_num, X_text.toarray()])  # –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å sparse
            X = np.nan_to_num(X, nan=0.0)
            y = df['averageRating'].values

            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            split_idx = int(len(X) * (1 - val_split))
            X_train, X_val = X[:split_idx], X[split_idx:]
            y_train, y_val = y[:split_idx], y[split_idx:]

            self.predictor.partial_fit(X_train, y_train)

            y_pred = self.predictor.predict(X_val)
            mae = np.mean(np.abs(y_val - y_pred))
            val_history.append(mae)

            tqdm.write(f"Chunk {total_chunks + 1:2d} | MAE: {mae:.3f}")
            total_chunks += 1

            del df, X, y, X_train, X_val, y_train, y_val
            gc.collect()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ä–µ–¥–Ω–∏–µ
        self.director_avg = {k: np.mean(v) for k, v in director_ratings.items()}
        print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
        print(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π MAE: {np.mean(val_history[-3:]):.3f}")
        
    def predict_rating(
        self,
        title: str,
        director: str = "Unknown",
        year: int = 2020,
        runtime: int = 120,
        description: str = ""
    ) -> float:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ —Ñ–∏–ª—å–º–∞.
        """
        if not self.predictor or not self.vectorizer:
            raise RuntimeError("Model not trained. Call .train_on_chunks() first.")

        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        year = year if pd.notna(year) else 2000
        runtime = runtime if pd.notna(runtime) else 90
        director = str(director) if pd.notna(director) else "Unknown"
        description = str(description) if description else str(title)

        # –ü—Ä–∏–∑–Ω–∞–∫–∏
        is_remake = 1 if 'remake' in title.lower() else 0
        director_avg = self.director_avg.get(director, np.mean(list(self.director_avg.values())))

        # NLP
        text_vec = self.vectorizer.transform(pd.Series([description]))

        # –§–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
        X_num = np.array([[year, runtime, director_avg, is_remake]])
        X = np.hstack([X_num, text_vec])

        rating = self.predictor.predict(X)[0]
        return round(max(1.0, min(10.0, rating)), 1)

    def save(self, path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å—é –º–æ–¥–µ–ª—å —Ü–µ–ª–∏–∫–æ–º."""
        joblib.dump({
            'model': self.predictor,
            'vectorizer': self.vectorizer,
            'director_avg': self.director_avg
        }, path)