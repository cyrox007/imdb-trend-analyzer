# kinovanga/predictor.py
import pandas as pd
import numpy as np
import joblib
import gc
from tqdm import tqdm

# –í–Ω–µ—à–Ω–∏–µ –∏–º–ø–æ—Ä—Ç—ã –≤–≤–µ—Ä—Ö—É
from app.data_loader import load_imdb_chunked
from app.preprocessing import create_features
from app.nlp import PlotVectorizer
from app.model import MovieRatingPredictor


class Kinovanga:
    def __init__(self, model_path: str = None):
        if model_path:
            data = joblib.load(model_path)
            self.predictor = data['model']
            self.vectorizer = data['vectorizer']
            self.director_avg = data['director_avg']
        else:
            self.predictor = None
            self.vectorizer = None
            self.director_avg = {}

    def train_on_chunks(
        self,
        basics_path: str,
        ratings_path: str,
        crew_path: str,
        chunksize: int = 10000,
        max_chunks: int = None,
        val_split: float = 0.2
    ):
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —á–∞–Ω–∫–∞—Ö —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º.
        """
        print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –ö–∏–Ω–æ–í–∞–Ω–≥–∏ –Ω–∞ —á–∞–Ω–∫–∞—Ö...")
        print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {chunksize}")
        print(f"  ‚Ä¢ –ú–∞–∫—Å–∏–º—É–º —á–∞–Ω–∫–æ–≤: {max_chunks if max_chunks else '–≤—Å–µ'}")
        print(f"  ‚Ä¢ –í–∞–ª–∏–¥–∞—Ü–∏—è: {val_split * 100:.0f}%")

        # --- 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞ ---
        print("üß† –û–±—É—á–∞—é TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –Ω–∞ –ø–µ—Ä–≤–æ–º —á–∞–Ω–∫–µ...")
        chunk_iter = load_imdb_chunked(basics_path, ratings_path, crew_path, chunksize)
        df_chunk = next(chunk_iter)
        df_chunk = create_features(df_chunk)

        if 'description' not in df_chunk.columns:
            raise KeyError("–ö–æ–ª–æ–Ω–∫–∞ 'description' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ create_features().")

        self.vectorizer = PlotVectorizer(max_features=100)
        self.vectorizer.fit_transform(df_chunk['description'])

        # --- 2. –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Ä–µ–∂–∏—Å—Å—ë—Ä–∞–º ---
        print("üìä –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–µ–∂–∏—Å—Å—ë—Ä–∞–º...")
        all_director_data = []
        chunk_iter = load_imdb_chunked(basics_path, ratings_path, crew_path, chunksize)
        for i, chunk in enumerate(chunk_iter):
            processed = create_features(chunk)  # –ü—Ä–æ—Å—Ç–æ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
            all_director_data.append(processed[['directors', 'averageRating']])
            if max_chunks and i >= max_chunks:
                break
        full_df = pd.concat(all_director_data, ignore_index=True)
        self.director_avg = full_df.groupby('directors')['averageRating'].mean().to_dict()

        # --- 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ ---
        self.predictor = MovieRatingPredictor()
        val_history = []

        # --- 4. –û–±—É—á–µ–Ω–∏–µ –ø–æ —á–∞–Ω–∫–∞–º ---
        print("üèãÔ∏è –û–±—É—á–∞—é –º–æ–¥–µ–ª—å...")
        chunk_iter = load_imdb_chunked(basics_path, ratings_path, crew_path, chunksize)
        for i, chunk in enumerate(tqdm(chunk_iter, desc="üì¶ –ß–∞–Ω–∫–∏", total=max_chunks)):
            if max_chunks and i >= max_chunks:
                break

            # üî• –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø–µ—Ä–µ–¥–∞—á–µ–π director_avg
            df = create_features(chunk, director_avg_map=self.director_avg)

            # –¢–µ–ø–µ—Ä—å director_avg_rating —Ç–æ—á–Ω–æ –µ—Å—Ç—å
            X_text = self.vectorizer.transform(df['description'])
            X_num = df[['startYear', 'runtimeMinutes', 'director_avg_rating', 'is_remake']].values
            X = np.hstack([X_num, X_text])
            X = np.nan_to_num(X, nan=0.0)
            y = df['averageRating'].values

            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            split_idx = int(len(X) * (1 - val_split))
            X_train, X_val = X[:split_idx], X[split_idx:]
            y_train, y_val = y[:split_idx], y[split_idx:]

            self.predictor.partial_fit(X_train, y_train)

            # –û—Ü–µ–Ω–∫–∞
            y_pred = self.predictor.predict(X_val)
            mae = np.mean(np.abs(y_val - y_pred))
            val_history.append(mae)

            tqdm.write(f"Chunk {i+1:2d} | MAE: {mae:.3f}")

            del df, X, y, X_train, X_val, y_train, y_val
            import gc; gc.collect()

        print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
        print(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–π MAE: {np.mean(val_history[-3:]):.3f}")

    def predict_rating(
        self,
        title: str,
        director: str = "Unknown",
        year: int = 2020,
        runtime: int = 120,
        description: str = ""
    ) -> float:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ —Ñ–∏–ª—å–º–∞.
        """
        if not self.predictor or not self.vectorizer:
            raise RuntimeError("Model not trained. Call .train_on_chunks() first.")

        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        year = year if pd.notna(year) else 2000
        runtime = runtime if pd.notna(runtime) else 90
        director = str(director) if pd.notna(director) else "Unknown"
        description = str(description) if description else str(title)

        # –ü—Ä–∏–∑–Ω–∞–∫–∏
        is_remake = 1 if 'remake' in title.lower() else 0
        director_avg = self.director_avg.get(director, np.mean(list(self.director_avg.values())))

        # NLP
        text_vec = self.vectorizer.transform(pd.Series([description]))

        # –§–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ–∫—Ç–æ—Ä
        X_num = np.array([[year, runtime, director_avg, is_remake]])
        X = np.hstack([X_num, text_vec])

        rating = self.predictor.predict(X)[0]
        return round(max(1.0, min(10.0, rating)), 1)

    def save(self, path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å—é –º–æ–¥–µ–ª—å —Ü–µ–ª–∏–∫–æ–º."""
        joblib.dump({
            'model': self.predictor,
            'vectorizer': self.vectorizer,
            'director_avg': self.director_avg
        }, path)